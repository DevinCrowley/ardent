{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/c7/198496417c9c2f6226616cff7dedf2115a4f4d0276613bab842ec8ac1e23/numpy-1.16.4-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 77kB/s \n",
      "\u001b[?25hCollecting torch\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/ff/92aea60792d3b45c44ded21d6248690f69a6153af9685aad1424507ffe84/torch-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl (676.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 676.9MB 2.1kB/s \n",
      "\u001b[?25hCollecting scipy\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/81/39/f1457091d0a45a84a2bd7815e2cf6bd45d4fe240728e9ed567cbb17c8abe/scipy-1.2.1-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.8MB 51kB/s \n",
      "\u001b[?25hCollecting sklearn\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "Collecting nibabel\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/66/30/fbed62172920c3fd050b6483541546a87c5e735f4a0ef03f08bb150680b4/nibabel-2.4.1-py2.py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 435kB/s \n",
      "\u001b[?25hCollecting nilearn\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/65/ba76e7cd544dafc28960e60b099d6f906a2096034c560158beaf2ff299bc/nilearn-0.5.2-py2.py3-none-any.whl (2.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.4MB 599kB/s \n",
      "\u001b[?25hCollecting matplotlib\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/32/6b/0368cfa5e1d1ae169ab7dc78addda3fd5e6262e48d7373a9114bac7caff7/matplotlib-2.2.4-cp27-cp27mu-manylinux1_x86_64.whl (12.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.8MB 85kB/s \n",
      "\u001b[?25hCollecting future (from torch)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 1.4MB/s \n",
      "\u001b[?25hCollecting scikit-learn (from sklearn)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/bb/52a01390c1dbb2c65d3072bc687271aa9ddf6964141ce7e03304820138f4/scikit_learn-0.20.3-cp27-cp27mu-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 187kB/s \n",
      "\u001b[?25hCollecting bz2file; python_version < \"3.0\" (from nibabel)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Collecting six>=1.3 (from nibabel)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting backports.functools-lru-cache (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/8e/2424c0e65c4a066e28f539364deee49b6451f8fcd4f718fefa50cc3dcf48/backports.functools_lru_cache-1.5-py2.py3-none-any.whl\n",
      "Collecting subprocess32 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 5.4MB/s \n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/78/cb9248b2289ec31e301137cedbe4ca503a74ca87f88cdbfd2f8be52323bf/kiwisolver-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl (93kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 6.3MB/s \n",
      "\u001b[?25hCollecting pytz (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 2.1MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.1 (from matplotlib)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 6.3MB/s \n",
      "\u001b[?25hCollecting setuptools (from kiwisolver>=1.0.1->matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: future, bz2file, subprocess32\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dcrowley/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dcrowley/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "  Running setup.py bdist_wheel for subprocess32 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dcrowley/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
      "Successfully built future bz2file subprocess32\n",
      "Installing collected packages: numpy, future, torch, scipy, scikit-learn, sklearn, bz2file, six, nibabel, nilearn, cycler, backports.functools-lru-cache, subprocess32, setuptools, kiwisolver, pytz, python-dateutil, pyparsing, matplotlib\n",
      "Successfully installed backports.functools-lru-cache-1.5 bz2file-0.98 cycler-0.10.0 future-0.17.1 kiwisolver-1.1.0 matplotlib-2.2.4 nibabel-2.4.1 nilearn-0.5.2 numpy-1.16.4 pyparsing-2.4.0 python-dateutil-2.8.0 pytz-2019.1 scikit-learn-0.20.3 scipy-1.2.1 setuptools-41.0.1 six-1.12.0 sklearn-0.0 subprocess32-3.5.4 torch-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#%% Setup.\n",
    "\n",
    "# Activate environment.\n",
    "! . ~/env/bin/activate\n",
    "\n",
    "# Install requirements.\n",
    "\n",
    "! pip install --upgrade numpy torch scipy sklearn nibabel nilearn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcrowley/ARDENT_gpu_test/env/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#%% Imports.\n",
    "\n",
    "import numpy as np\n",
    "import ardent\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare template and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load template and target arrays from file.\n",
    "\n",
    "Note: in this demo we use the Allen mouse brain atlas for the template, and thus the words 'atlas' and 'template' are effectively interchangable hereafter.\n",
    "\n",
    "'atlas' is used in the code of this demo, whereas 'template' is used internally to ardent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 264, 228) (228, 160, 270)\n",
      "(160, 264, 228) (228, 160, 270)\n"
     ]
    }
   ],
   "source": [
    "#%% Load template and target.\n",
    "\n",
    "directory_path = Path('/home/dcrowley/image_lddmm_tensorflow')\n",
    "atlas_image_filename = 'average_template_50.img'\n",
    "target_image_filename = '180517_Downsample.img'\n",
    "\n",
    "atlasPath = directory_path / atlas_image_filename\n",
    "targetPath = directory_path / target_image_filename\n",
    "\n",
    "atlas = ardent.load(atlasPath)\n",
    "target = ardent.load(targetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess template and target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Reform and normalize images.\n",
    "\n",
    "atlas = ardent.basic_preprocessing(atlas)\n",
    "target = ardent.basic_preprocessing(target)\n",
    "\n",
    "# If you are wondering, the above does the same thing as below:\n",
    "'''\n",
    "# Normalize.\n",
    "# Compute mean absolute deviation.\n",
    "atlas_mean_absolute_deviation = np.mean(np.abs(atlas - np.median(atlas)))\n",
    "target_mean_absolute_deviation = np.mean(np.abs(target - np.median(target)))\n",
    "# Subtract mean.\n",
    "atlas -= np.mean(atlas)\n",
    "target -= np.mean(target)\n",
    "# Divide by mean absolute deviation.\n",
    "atlas /= atlas_mean_absolute_deviation\n",
    "target /= target_mean_absolute_deviation\n",
    "\n",
    "# Pad with zeros.\n",
    "atlas = np.pad(atlas, pad_width=5, mode='constant', constant_values=0)\n",
    "target = np.pad(target, pad_width=5, mode='constant', constant_values=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orient target to template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualize images before registration.\n",
    "# It is important to check that the images are oriented to one another \n",
    "# and do not require rotating or flipping.\n",
    "\n",
    "ardent.heatslices(atlas, title='atlas', limit_mode='stdev')\n",
    "ardent.heatslices(target, title='target', limit_mode='stdev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorient target and revisualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Orient images.\n",
    "# From looking at the two images we can see that they are not oriented.\n",
    "# This must be corrected prior to performing the registration.\n",
    "\n",
    "# Here we will orient the target to the template (atlas).\n",
    "reoriented_target = np.copy(target)\n",
    "reoriented_target = np.rot90(reoriented_target, axes=(1,2))\n",
    "reoriented_target = np.rot90(reoriented_target, axes=(2,0))\n",
    "# np.moveaxis does nothing when destination == source.\n",
    "# reoriented_target = np.moveaxis(reoriented_target, source=[0,1,2], destination=[0,1,2])\n",
    "reoriented_target = np.flip(reoriented_target, axis=0)\n",
    "reoriented_target = np.flip(reoriented_target, axis=1)\n",
    "\n",
    "# If we performed an odd number of inversions with the above lines, \n",
    "# we must perform a flip to correct for inverting the image. \n",
    "# The simplest flip is a sagittal flip, since that is the axis of innate symmetry in the brain.\n",
    "# In this case, we can see from the atlas visualization that this is axis 2 (the last row).\n",
    "# The above lines performed 2 inversions, so the following line is commented out.\n",
    "# reoriented_target = np.flip(reoriented_target, axis=2)\n",
    "\n",
    "# Verify proper orientation.\n",
    "ardent.heatslices(atlas, title='atlas', limit_mode='stdev')\n",
    "ardent.heatslices(reoriented_target, title='reoriented target', limit_mode='stdev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use reoriented target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use reoriented target.\n",
    "# Once we've finished orienting target, we use the result as target.\n",
    "# A copy is taken to get a real array rather than a view.\n",
    "target = reoriented_target.copy()\n",
    "\n",
    "# Pad images to same shape.\n",
    "atlas, target = ardent.lddmm.torch_lddmm_wrapper._pad_to_same_shape(atlas, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Perform registration.\n",
    "\n",
    "# Instantiate Transform object.\n",
    "transform = ardent.Transform()\n",
    "\n",
    "transform.register(template=atlas, target=target, \n",
    "    sigmaR=1e6, eV=0.1, niter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Apply the transformation.\n",
    "# The transformation is the result of the registration, and it can be applied to arbitrary images, \n",
    "# although presently they should be preprocessed as the atlas and target were.\n",
    "# Here we will simply apply the transformation to both the atlas and target, \n",
    "# making them match up with each other.\n",
    "# i.e. deformed_target should resemble atlas, and deformed_atlas should resemble target.\n",
    "\n",
    "deformed_atlas = transform.apply_transform(subject=atlas, deform_to='target', save_path=None)\n",
    "deformed_target = transform.apply_transform(subject=target, deform_to='template', save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualize results.\n",
    "\n",
    "ardent.heatslices(deformed_atlas, title='deformed_atlas', limit_mode='stdev')\n",
    "ardent.heatslices(deformed_target, title='deformed_target', limit_mode='stdev')\n",
    "\n",
    "# To simply visualize error we plot the difference between images.\n",
    "ardent.heatslices(deformed_target - atlas, title='error in atlas space', limit_mode='stdev')\n",
    "ardent.heatslices(target - deformed_atlas, title='error in target space', limit_mode='stdev')\n",
    "ardent.heatslices(target - atlas, title='error before registration', limit_mode='stdev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ardent",
   "language": "python",
   "name": "ardent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
